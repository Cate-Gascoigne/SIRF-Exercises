{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiac MRF Workshop 2022-C\n",
    "\n",
    "This notebook covers what is being done in `rec_mrf_im` and `match_sig` in `cMRF_Workshop2022_helper`. Here we will load a MRF scan which we have simulated before and go through reconstruction and template matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import shutil, os\n",
    "from pathlib import Path \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import sirf.Reg as pReg\n",
    "import sirf.DynamicSimulation as pDS\n",
    "import sirf.Gadgetron as pMR\n",
    "from cil.utilities.jupyter import islicer, link_islicer\n",
    "\n",
    "import auxiliary_functions as aux\n",
    "import cMRF_Workshop2022_helper as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main paths\n",
    "# Where is all the data\n",
    "fpath_base = Path('/mnt/share/SA/')\n",
    "\n",
    "# Where are we saving (intermediate) results\n",
    "root_path = Path('/home/sirfuser/devel/Data_mrf_sim/')\n",
    "root_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "# These folders will be filled with the formatted input \n",
    "# for the simulation and will then also contain the output of the simulation\n",
    "fpath_in = root_path / \"Input\"\n",
    "fpath_in.mkdir(exist_ok=True, parents=True)\n",
    "fpath_out = root_path / \"Output\"\n",
    "fpath_out.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tissue parameters (T1, T2, Rho) : xml\n",
    "fname_xml = fpath_base / 'XCat/XCAT_TissueParameters_XML.xml'\n",
    "# 3D tissue segmentation : nifti\n",
    "fpath_segmentation_nii = fpath_base / 'XCat/label_volume_sa.nii'\n",
    "# Respiratory motion fields : nifti\n",
    "fpath_resp_mvf = fpath_base / 'XCat/mvf_resp/'\n",
    "# Cardiac motion fields : nifti\n",
    "fpath_card_mvf = fpath_base / 'XCat/mvf_card/'\n",
    "\n",
    "# MR raw k-space data file as acquisition template : ismrmrd\n",
    "fname_acquisition_template = fpath_base / 'templates/acquisition_template.h5'\n",
    "\n",
    "# MRF parameters used for EPG simulation\n",
    "fname_epg_par = fpath_base / 'Fingerprinting/XCAT_tissue_parameter_list.npz'\n",
    "# MRF signals describing signal behaviour of tissue types in segmentation simulated with EPG\n",
    "fname_epg_sig = fpath_base / 'Fingerprinting/XCAT_tissue_parameter_fingerprints.npy'\n",
    "# MRF dictionary for matching and parameter estimation\n",
    "fname_dict = fpath_base / 'Fingerprinting/dict_70_1500.npz'\n",
    "\n",
    "# Prefix for ground truth T1, T2 and rho maps\n",
    "prefix_ground_truth = fpath_out / 'simulation_gt'\n",
    "\n",
    "\n",
    "fname_sim = fpath_base / 'Fingerprinting/mrf_simulation.h5'\n",
    "filenames_parametermaps = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Clean up folders\n",
    "\n",
    "When we set up the simulation, we need to save several files temporarily. To make sure we don't run into any problems from previous simulations, we go through all the folders and clean them. When you run the following cell you will be asked if you want to delete any old content. Just say 'y' to agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.clear_folders([fpath_in, fpath_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B Load the simulated MRF raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data = pMR.AcquisitionData(str(fname_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C Carry out image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First compute the CSM based on all data\n",
    "csm = pMR.CoilSensitivityData()\n",
    "csm.smoothness = 50\n",
    "csm.calculate(simulated_data)\n",
    "csm_arr = csm.as_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't reconstruct one image per radial spoke but set the total number of reconstructed images with the paramter `num_recon_imgs`. The higher this values, the fewer radial lines per image are used and the more accurate the temporal behaviour of the MRF signal is recovered. But of course also the worse the quality of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then activate the time-resolved reconstruction in repetition dimension\n",
    "num_recon_imgs = 250\n",
    "simulated_data = aux.activate_timeresolved_reconstruction(simulated_data, num_recon_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a new CSM based on the time-resolved acquisition data\n",
    "csm = pMR.CoilSensitivityData()\n",
    "\n",
    "# This step sets up a time-resolved coilmap. The reconstruction checks if for each\n",
    "# time point a coilmap is present. \n",
    "csm.calculate(simulated_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we want to use the coilmap that was computed from the entire dataset\n",
    "# so we give every repetition the same coilmap\n",
    "num_reps = csm.as_array().shape[1]\n",
    "csm_arr = np.tile(csm_arr, (1,num_reps,1,1))\n",
    "\n",
    "# Unfortunately these two axes have to be swapped.\n",
    "csm_arr = np.swapaxes(csm_arr, 0, 1)\n",
    "csm = csm.fill(csm_arr.astype(csm.as_array().dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will carry out a basic image reconstruction by simply doing gridding of the radial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "recon = aux.reconstruct_data(simulated_data, csm)\n",
    "print(f'Image reconstruction took {time.time()-tstart} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructed images `recon` are an `ImageData` object. In order to get the image information as a numpy array we use the function `as_array()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_result = recon.as_array()\n",
    "recon_result = np.abs(recon_result)\n",
    "print(f'The shape of the reconstructed image is {recon_result.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can visualise it. We will visualse a single image, a view of a line through the image over time (to see the contrast dynamics) and the sum over all dynamic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.vis_mrf_im_data(recon_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above reconstruction is simply doing gridding. We can do better by using some iterative algorithms such as iterative SENSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "recon = aux.iterative_reconstruct_data(simulated_data, csm)\n",
    "print(f'Image reconstruction took {time.time()-tstart} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course it took a bit longer but hopefully the quality is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.vis_mrf_im_data(np.abs(recon.as_array()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D Dictionary matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the matching we have to load a pre-computed dictionary. Since we used a sliding window to reconstruct images at lower temporal resolution, but higher image quality the pre-computed dictionary must be brought to the same temporal resolution. This can be done with an auxiliary function does this based on the AcquisitionData we previously used for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary\n",
    "mrfdict = np.load(fname_dict)\n",
    "\n",
    "dict_theta = mrfdict['dict_theta']\n",
    "dict_mrf = mrfdict['dict_norm']\n",
    "dict_mrf = np.transpose( aux.apply_databased_sliding_window(simulated_data, np.transpose(dict_mrf)))\n",
    "\n",
    "dict_mrf = dict_mrf[0:100,:]\n",
    "dict_theta = dict_theta[0:100,:]\n",
    "print(\"Our dictionary to match is of size {}\".format(dict_mrf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to convert the image in the shape `(#time points, #pixels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_series = recon.as_array()\n",
    "img_shape = img_series.shape[1:]\n",
    "img_series_1d = np.transpose(np.reshape(img_series,(img_series.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This checks the largest overlap between time-profile and dictionary entries\n",
    "# if the RAM overflows this will catch it and perform the task in multiple sets.\n",
    "m0_t1_t2_map_matched = aux.match_dict(dict_mrf, dict_theta, img_series_1d)\n",
    "m0_t1_t2_map_matched = np.reshape(m0_t1_t2_map_matched, (*img_shape, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.vis_m0_t1_t2_mrf_maps([m0_t1_t2_map_matched,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also load the ground truth maps to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0_t1_t2_map_gt = helper.load_gt_maps(filenames_parametermaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.vis_m0_t1_t2_mrf_maps([m0_t1_t2_map_gt, m0_t1_t2_map_matched,], method_titles=['Ground truth', 'Motion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "In this notebook we:\n",
    "\n",
    "- carried out image reconstruction\n",
    "- estimated T1, T2 and M0 based on a pre-calculated dictionary\n",
    "- visualised the obtained maps\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
