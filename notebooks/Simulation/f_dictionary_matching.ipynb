{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook F: Dictionary Matching\n",
    "\n",
    "#### Prerequisites:\n",
    "- a simulated rawdata file containing time-varying magnetisation.\n",
    "- a pre-computed dictionary of time-resolved magnetisation for many tissue parameter combinations.\n",
    "\n",
    "#### Goals:\n",
    "- reconstruct time-resolved images containing the MRF signal.\n",
    "\n",
    "#### Content overview: \n",
    "- loading previously reconstructed data\n",
    "- averaging the dictionary to the same temporal resolution as the reconstructions\n",
    "- creating T1 and T2 maps from previously simulated data using dictionary matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os \n",
    "import auxiliary_functions as aux\n",
    "\n",
    "import numpy as np \n",
    "import sirf.Gadgetron as pMR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this is where we store the properly formatted data\n",
    "root_path = aux.root_path\n",
    "fpath_input = root_path / \"Output\"\n",
    "fpath_output = fpath_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the images we reconstructed before\n",
    "fname_ad = fpath_input / \"output_e_timeresolved_mrf_simulation.h5\"\n",
    "ad = pMR.AcquisitionData(str(fname_ad))\n",
    "\n",
    "fname_simulated_recon = fpath_input / \"output_e_timeresolved_recon_mrf_simulation.npy\"\n",
    "recon_arr = np.load(fname_simulated_recon)\n",
    "recon = pMR.ImageData()\n",
    "recon.from_acquisition_data(ad)\n",
    "recon = recon.fill(recon_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the matching we have to load a pre-computed dictionary. Since we used a sliding window to reconstruct images at lower temporal resolution, but higher image quality the pre-computed dictionary must be brought to the same temporal resolution. This can be done with an auxiliary function does this based on the AcquisitionData we previously used for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "fname_dict = Path(\"/media/sf_CCPPETMR/TestData/Input/xDynamicSimulation/pDynamicSimulation/Fingerprints/dict_70_1500.npz\")\n",
    "mrfdict = np.load(fname_dict)\n",
    "\n",
    "dict_theta = mrfdict['dict_theta']\n",
    "\n",
    "dict_mrf = mrfdict['dict_norm']\n",
    "dict_mrf = np.transpose( aux.apply_databased_sliding_window(ad, np.transpose(dict_mrf)))\n",
    "\n",
    "dict_us_factor = 10\n",
    "dict_mrf = dict_mrf[0:-1:dict_us_factor,:]\n",
    "dict_theta = dict_theta[0:-1:dict_us_factor,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to convert the image in the shape `(#time points, #pixels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our dictionary to match is of size {}\".format(dict_mrf.shape))\n",
    "img_series = recon.as_array()\n",
    "img_shape = img_series.shape[1:]\n",
    "img_series_1d = np.transpose(np.reshape(img_series,(img_series.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this checks the largest overlap between time-profile and dictionary entries\n",
    "# if the RAM overflows this will catch it and perform the task in multiple sets.\n",
    "dict_match = aux.match_dict(dict_mrf, dict_theta, img_series_1d)\n",
    "dict_match = np.reshape(dict_match, (*img_shape, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "f,ax = plt.subplots(1,2)\n",
    "\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "im = ax[0].imshow(np.abs(dict_match[:,:,1])/1000,cmap='jet',vmin=0,vmax=2.5)\n",
    "cbar = f.colorbar(im, cax=cax, ticks=[0, 0.8, 1.6, 2.4])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"T1 (s)\")\n",
    "\n",
    "\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "im = ax[1].imshow(np.abs(dict_match[:,:,2]),cmap='magma',vmin=0,vmax=150)\n",
    "cbar = f.colorbar(im, cax=cax, ticks=[0, 50, 100, 150])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"T2 (ms)\")\n",
    "\n",
    "fig_path = root_path / \"Figures\"\n",
    "fig_path.mkdir(exist_ok=True)\n",
    "\n",
    "fname_out = fig_path / \"fig_f_dictionary_matching_static.png\"\n",
    "plt.savefig(str(fname_out), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "T1GT = nib.load(str(fpath_input/ \"output_c_static_ground_truth_T1_ms.nii\"))\n",
    "T2GT = nib.load(str(fpath_input/ \"output_c_static_ground_truth_T2_ms.nii\"))\n",
    "\n",
    "f,ax = plt.subplots(2,2)\n",
    "\n",
    "ax[0,0].imshow(np.abs(dict_match[:,:,1]),cmap='jet',vmin=0,vmax=2500)\n",
    "ax[0,0].axis(\"off\")\n",
    "ax[0,0].set_title(\"T1\")\n",
    "\n",
    "divider = make_axes_locatable(ax[0,1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "im = ax[0,1].imshow(np.transpose(np.abs(np.squeeze(T1GT.get_fdata()))),cmap='jet',vmin=0,vmax=2500)\n",
    "cbar = f.colorbar(im, cax=cax, ticks=[0, 800, 1600, 2400])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.set_label(f'T1(ms)')\n",
    "\n",
    "ax[0,1].axis(\"off\")\n",
    "ax[0,1].set_title(\"T1 GT\")\n",
    "\n",
    "ax[1,0].imshow(np.abs(dict_match[:,:,2]),cmap='magma',vmin=0,vmax=150)\n",
    "ax[1,0].axis(\"off\")\n",
    "ax[1,0].set_title(\"T2\")\n",
    "\n",
    "\n",
    "divider = make_axes_locatable(ax[1,1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "im = ax[1,1].imshow(np.transpose(np.abs(np.squeeze(T2GT.get_fdata()))),cmap='magma',vmin=0,vmax=150)\n",
    "cbar = f.colorbar(im, cax=cax, ticks=[0, 50, 100, 150])\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.set_label(f'T2(ms)')\n",
    "\n",
    "\n",
    "ax[1,1].axis(\"off\")\n",
    "ax[1,1].set_title(\"T2 GT\")\n",
    "\n",
    "fig_path = root_path / \"Figures\"\n",
    "fig_path.mkdir(exist_ok=True)\n",
    "\n",
    "fname_out = fig_path / \"fig_f_dictionary_matching_static_comparison.png\"\n",
    "plt.savefig(str(fname_out), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = nib.Nifti1Image(np.abs(dict_match[...,1]), np.eye(4))\n",
    "fname_output = fpath_output / \"output_f_fit_T1.nii\"\n",
    "nib.save(img,fname_output)\n",
    "\n",
    "img = nib.Nifti1Image(np.abs(dict_match[...,2]), np.eye(4))\n",
    "fname_output = fpath_output / \"output_f_fit_T2.nii\"\n",
    "nib.save(img,fname_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "In this notebook we \n",
    "- averaged a high-resolution dictionary to the temporal resolution we reconstructed.\n",
    "- performed dictionary matching to compute T1 and T2 maps.\n",
    "- compared results of dictionary matching with ground truth T1 and T2 maps.\n",
    "\n",
    "_Up next: combining motion and time-dependent magnetisation._"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
