{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notbook F: Dictionary Matching\n",
    "\n",
    "#### Prerequisites:\n",
    "- a simulated rawdata file containing time-varying magnetisation.\n",
    "- a pre-computed dictionary of time-resolved magnetisation for many tissue parameter combinations.\n",
    "\n",
    "#### Goals:\n",
    "- reconstruct time-resolved images containing the MRF signal.\n",
    "\n",
    "#### Content overview: \n",
    "- loading previously reconstructed data\n",
    "- averaging the dictionary to the same temporal resolution as the reconstructions\n",
    "- creating T1 and T2 maps from previously simulated data using dictionary matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os \n",
    "import auxiliary_functions as aux\n",
    "\n",
    "import numpy as np \n",
    "import sirf.Gadgetron as pMR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this is where we store the properly formatted data\n",
    "root_path = Path(os.getenv(\"SIRF_INSTALL_PATH\"))\n",
    "root_path = root_path / \"share/SIRF-3.1/Simulation/\"\n",
    "fpath_input = root_path / \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the images we reconstructed before\n",
    "fname_ad = fpath_input / \"output_e_timeresolved_mrf_simulation.h5\"\n",
    "ad = pMR.AcquisitionData(str(fname_ad))\n",
    "\n",
    "fname_simulated_recon = fpath_input / \"output_e_timeresolved_recon_mrf_simulation.npy\"\n",
    "recon_arr = np.load(fname_simulated_recon)\n",
    "recon = pMR.ImageData()\n",
    "recon.from_acquisition_data(ad)\n",
    "recon = recon.fill(recon_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the matching we have to load a pre-computed dictionary. Since we used a sliding window to reconstruct images at lower temporal resolution, but higher image quality the pre-computed dictionary must be brought to the same temporal resolution. This can be done with an auxiliary function does this based on the AcquisitionData we previously used for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "fname_dict = Path(\"/media/sf_CCPPETMR/TestData/Input/xDynamicSimulation/pDynamicSimulation/Fingerprints/dict_70_1500.npz\")\n",
    "mrfdict = np.load(fname_dict)\n",
    "\n",
    "dict_theta = mrfdict['dict_theta']\n",
    "\n",
    "dict_mrf = mrfdict['dict_norm']\n",
    "dict_mrf = np.transpose( aux.apply_databased_sliding_window(ad, np.transpose(dict_mrf)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to convert the image in the shape `(#time points, #pixels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_series = recon.as_array()\n",
    "img_shape = img_series.shape[1:]\n",
    "img_series_1d = np.transpose(np.reshape(img_series,(img_series.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this checks the largest overlap between time-profile and dictionary entries\n",
    "# if the RAM overflows this will catch it and perform the task in multiple sets.\n",
    "dict_match = aux.match_dict(dict_mrf, dict_theta, img_series_1d)\n",
    "dict_match = np.reshape(dict_match, (*img_shape, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(np.abs(dict_match[:,:,1]),cmap='jet',vmin=400,vmax=1500)\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"T1\")\n",
    "ax[1].imshow(np.abs(dict_match[:,:,2]),cmap='viridis',vmin=10,vmax=150)\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"T2\")\n",
    "\n",
    "fig_path = root_path / \"Figures\"\n",
    "fig_path.mkdir(exist_ok=True)\n",
    "\n",
    "fname_out = fig_path / \"fig_f_dictionary_matching_static.png\"\n",
    "plt.savefig(str(fname_out), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "T1GT = nib.load(str(fpath_input/ \"output_c_static_ground_truth_T1_ms.nii\"))\n",
    "T2GT = nib.load(str(fpath_input/ \"output_c_static_ground_truth_T2_ms.nii\"))\n",
    "\n",
    "f,ax = plt.subplots(2,2)\n",
    "\n",
    "ax[0,0].imshow(np.abs(dict_match[:,:,1]),cmap='jet',vmin=400,vmax=1500)\n",
    "ax[0,0].axis(\"off\")\n",
    "ax[0,0].set_title(\"T1\")\n",
    "\n",
    "ax[1,0].imshow(np.abs(dict_match[:,:,2]),cmap='viridis',vmin=10,vmax=150)\n",
    "ax[1,0].axis(\"off\")\n",
    "ax[1,0].set_title(\"T2\")\n",
    "\n",
    "ax[0,1].imshow(np.transpose(np.abs(np.squeeze(T1GT.get_fdata()))),cmap='jet',vmin=400,vmax=1500)\n",
    "ax[0,1].axis(\"off\")\n",
    "ax[0,1].set_title(\"T1 GT\")\n",
    "\n",
    "ax[1,1].imshow(np.transpose(np.abs(np.squeeze(T2GT.get_fdata()))),cmap='viridis',vmin=10,vmax=150)\n",
    "ax[1,1].axis(\"off\")\n",
    "ax[1,1].set_title(\"T2 GT\")\n",
    "\n",
    "fig_path = root_path / \"Figures\"\n",
    "fig_path.mkdir(exist_ok=True)\n",
    "\n",
    "fname_out = fig_path / \"fig_f_dictionary_matching_static_comparison.png\"\n",
    "plt.savefig(str(fname_out), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = nib.Nifti1Image(np.abs(dict_match[...,1]), np.eye(4))\n",
    "nib.save(img,\"/media/sf_CCPPETMR/TMP_T1_FIT.nii\")\n",
    "\n",
    "img = nib.Nifti1Image(np.abs(dict_match[...,2]), np.eye(4))\n",
    "nib.save(img,\"/media/sf_CCPPETMR/TMP_T2_FIT.nii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "In this notebook we \n",
    "- averaged a high-resolution dictionary to the temporal resolution we reconstructed.\n",
    "- performed dictionary matching to compute T1 and T2 maps.\n",
    "- compared results of dictionary matching with ground truth T1 and T2 maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
